{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hSVM and logistic regression\n",
    "> Benchmarking two more hyperbolic classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hSVM and hMLR benchmark:\n",
    "\n",
    "This code should be run using the `hsvm` conda environment instead of the `hdt` conda environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# hSVM stuff\n",
    "sys.path.append(\"../hsvm\")\n",
    "from hsvm import LinearHSVM\n",
    "\n",
    "# hLR stuff\n",
    "sys.path.append(\"../HyperbolicCV/code\")\n",
    "from lib.lorentz.layers.LMLR import LorentzMLR\n",
    "from lib.lorentz.manifold import CustomLorentz\n",
    "import torch\n",
    "\n",
    "# Euclidean versions\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# For benchmarking\n",
    "# from hyperdt.toy_data import wrapped_normal_mixture\n",
    "sys.path.append(\"../HoroRF\")\n",
    "from datasets.gaussian import get_training_data, get_testing_data\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress UserWarning from sklearn and FutureWarning from numba\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train hMLR function\n",
    "\n",
    "\n",
    "def train_hmlr(X, y, steps=1000):\n",
    "    # Init class...\n",
    "    hmlr = LorentzMLR(num_features=X.shape[1], num_classes=2, manifold=CustomLorentz())\n",
    "\n",
    "    # hMLR outputs logits; labels are {0, 1}\n",
    "    opt = torch.optim.Adam(hmlr.parameters(), lr=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for _ in range(steps):\n",
    "        opt.zero_grad()\n",
    "        logits = hmlr(X)\n",
    "        loss = loss_fn(logits[:, 1], y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return hmlr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942dfb27cf3041e69186142332e090a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=800), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=[\"seed\", \"n_dim\", \"model\", \"f1_score\", \"time\"])\n",
    "\n",
    "seeds = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "dims = [2, 4, 8, 16]\n",
    "my_tqdm = tqdm(total=len(seeds) * len(dims) * 4 * 5)\n",
    "\n",
    "for n_dim in dims:\n",
    "    for seed in seeds:\n",
    "        # print(n_dim, seed)\n",
    "        my_tqdm.set_description(f\"{n_dim}, {seed}\")\n",
    "        X, y = get_training_data(class_label=n_dim, seed=seed, num_samples=int(800 / 0.8), convert_to_poincare=False)\n",
    "\n",
    "        # Both models like hyperboloids, so this is easy\n",
    "        folds = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "        for train_index, test_index in folds.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            X_train_torch = torch.tensor(X_train, dtype=torch.float)\n",
    "            y_train_torch = torch.tensor(y_train, dtype=torch.float)\n",
    "            X_test_torch = torch.tensor(X_test, dtype=torch.float)\n",
    "            y_test_torch = torch.tensor(y_test, dtype=torch.float)\n",
    "\n",
    "            # hSVM\n",
    "            t1 = time.time()\n",
    "            hsvm = LinearHSVM() # From grid search\n",
    "            y_train_hsvm = y_train.detach().clone()\n",
    "            y_train_hsvm[y_train_hsvm == 0] = -1\n",
    "            hsvm.fit(X_train, y_train_hsvm)\n",
    "            y_pred = hsvm.predict(X_test)\n",
    "            t2 = time.time()\n",
    "            y_pred[y_pred == -1] = 0  # hMLR outputs {-1, 1}, but we want {, 1}\n",
    "            hsvm_score = f1_score(y_test, y_pred, average=\"micro\")\n",
    "            results.loc[len(results)] = [seed, n_dim, \"hSVM\", hsvm_score, t2 - t1]\n",
    "            my_tqdm.update()\n",
    "\n",
    "            # SVM\n",
    "            t1 = time.time()\n",
    "            svm = SVC(kernel=\"linear\")\n",
    "            svm.fit(X_train, y_train)\n",
    "            y_pred = svm.predict(X_test)\n",
    "            t2 = time.time()\n",
    "            svm_score = f1_score(y_test, y_pred, average=\"micro\")\n",
    "            results.loc[len(results)] = [seed, n_dim, \"SVM\", svm_score, t2 - t1]\n",
    "\n",
    "            # hMLR\n",
    "            t1 = time.time()\n",
    "            hmlr = train_hmlr(X_train_torch, y_train_torch)\n",
    "            y_pred = hmlr(X_test_torch).argmax(dim=1).clone().detach().numpy()\n",
    "            t2 = time.time()\n",
    "            hmlr_score = f1_score(y_test, y_pred, average=\"micro\")\n",
    "            results.loc[len(results)] = [seed, n_dim, \"hMLR\", hmlr_score, t2 - t1]\n",
    "            my_tqdm.update()\n",
    "\n",
    "            # Logistic Regression\n",
    "            t1 = time.time()\n",
    "            lr = LogisticRegression()\n",
    "            lr.fit(X_train, y_train)\n",
    "            y_pred = lr.predict(X_test)\n",
    "            t2 = time.time()\n",
    "            lr_score = f1_score(y_test, y_pred, average=\"micro\")\n",
    "            results.loc[len(results)] = [seed, n_dim, \"LR\", lr_score, t2 - t1]\n",
    "\n",
    "            # Postfix\n",
    "            my_tqdm.set_postfix(hSVM=hsvm_score, hMLR=hmlr_score, SVM=svm_score, LR=lr_score)\n",
    "\n",
    "results.to_csv(\"../data/processed/hsvm_hmlr_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model  n_dim\n",
       "LR     2         90.1125\n",
       "       4         99.2000\n",
       "       8         99.9750\n",
       "       16        99.9875\n",
       "SVM    2         90.1000\n",
       "       4         99.2125\n",
       "       8         99.9500\n",
       "       16        99.9875\n",
       "hMLR   2         89.5000\n",
       "       4         98.6750\n",
       "       8         99.9750\n",
       "       16       100.0000\n",
       "hSVM   2         81.4250\n",
       "       4         97.1125\n",
       "       8         99.9875\n",
       "       16        99.0750\n",
       "Name: f1_score, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.groupby([\"model\", \"n_dim\"]).mean()[\"f1_score\"] * 100\n",
    "\n",
    "# Compare to horoDT:\n",
    "#   2   91.88\n",
    "#   4   99.30\n",
    "#   8   99.96\n",
    "#  16   100.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsvm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
