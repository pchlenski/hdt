{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HoroRF\n",
    "> Comparing two hyperbolic RF methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m2023-09-18 09:03:44,089 [hororf.rf_trainer]\u001b[0m 1 GPUs available\n",
      "\u001b[32;1m2023-09-18 09:03:44,089 [hororf.rf_trainer]\u001b[0m Using seed 17 on class 2\n",
      "\u001b[32;1m2023-09-18 09:03:44,094 [hororf.utils]\u001b[0m 977 datapoints in dataset 'datasets.polblogs_geomstats'\n",
      "\u001b[32;1m2023-09-18 09:03:44,094 [hororf.utils]\u001b[0m 977 datapoints in test dataset 'datasets.polblogs_geomstats'\n",
      "\u001b[32;1m2023-09-18 09:03:44,095 [hororf.rf_trainer]\u001b[0m 781 train and 196 test samples for fold 0\n",
      "\u001b[32;1m2023-09-18 09:06:06,657 [hororf.rf_trainer]\u001b[0m Hyperbolic tree f1 micro: 0.8878, f1 macro: 0.8870, AUPR: 0.0000. Mean depth of 6.00\n",
      "\u001b[32;1m2023-09-18 09:06:06,658 [hororf.rf_trainer]\u001b[0m 781 train and 196 test samples for fold 1\n",
      "\u001b[32;1m2023-09-18 09:08:48,420 [hororf.rf_trainer]\u001b[0m Hyperbolic tree f1 micro: 0.9337, f1 macro: 0.9332, AUPR: 0.0000. Mean depth of 6.00\n",
      "\u001b[32;1m2023-09-18 09:08:48,421 [hororf.rf_trainer]\u001b[0m 782 train and 195 test samples for fold 2\n",
      "\u001b[32;1m2023-09-18 09:11:20,500 [hororf.rf_trainer]\u001b[0m Hyperbolic tree f1 micro: 0.9385, f1 macro: 0.9384, AUPR: 0.0000. Mean depth of 6.00\n",
      "\u001b[32;1m2023-09-18 09:11:20,501 [hororf.rf_trainer]\u001b[0m 782 train and 195 test samples for fold 3\n",
      "\u001b[32;1m2023-09-18 09:13:49,974 [hororf.rf_trainer]\u001b[0m Hyperbolic tree f1 micro: 0.8974, f1 macro: 0.8974, AUPR: 0.0000. Mean depth of 6.00\n",
      "\u001b[32;1m2023-09-18 09:13:49,975 [hororf.rf_trainer]\u001b[0m 782 train and 195 test samples for fold 4\n",
      "\u001b[32;1m2023-09-18 09:16:31,936 [hororf.rf_trainer]\u001b[0m Hyperbolic tree f1 micro: 0.9385, f1 macro: 0.9383, AUPR: 0.0000. Mean depth of 6.00\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Run HoroRF:at 1000 \n",
    "cd HoroRF\n",
    "/home/phil/mambaforge/envs/hdt/bin/python train_hyp_rf.py -h\n",
    "mv ./logs/output ./logs/output_$(date +%Y%m%d_%H%M%S)_hororf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hrf 99.79 0.25\n",
      "results_micro 98.66 0.90\n",
      "rf 99.79 0.25\n"
     ]
    }
   ],
   "source": [
    "# For using hororf outputs\n",
    "# vals = [\n",
    "#     0.8878, 0.9337, 0.9385, 0.8974, 0.9385\n",
    "# ]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "dim = 16\n",
    "dataname = \"gaussian\"\n",
    "# dataname = \"neuroseed\"\n",
    "\n",
    "for suffix in [\"hrf\", \"results_micro\", \"rf\"]:\n",
    "    vals = np.loadtxt(f\"./HoroRF/logs/big_bench/hororf_{dataname}_{dim}/{suffix}.txt\", delimiter=\"\\t\")\n",
    "    print(suffix, f\"{np.mean(vals) * 100:.2f}\", f\"{np.std(vals)*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loader from file: datasets.neuroseed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 28.18it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 28.01it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 30.22it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 28.65it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 29.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperbolic: 0.867 +/- 0.012\n",
      "Euclidean: 0.885 +/- 0.016\n"
     ]
    }
   ],
   "source": [
    "# For 16-dimensional embeddings, HoroRF had a micro-F1 score of 0.675. Let's try ours:\n",
    "\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from src.hyperdt.forest import HyperbolicRandomForestClassifier\n",
    "from src.hyperdt.conversions import convert\n",
    "\n",
    "# Read params from yml file\n",
    "\n",
    "\n",
    "def evaluate_hdt():\n",
    "    params = yaml.safe_load(open(\"HoroRF/params.yml\", \"r\"))\n",
    "\n",
    "    # Dataset\n",
    "    print(f\"Using loader from file: {params['dataset_file']}\")\n",
    "    print()  # For tqdm compatibility\n",
    "    if params[\"dataset_file\"] == \"datasets.gaussian\":\n",
    "        from HoroRF.datasets.gaussian import get_training_data, get_testing_data\n",
    "    elif params[\"dataset_file\"] == \"datasets.neuroseed\":\n",
    "        from HoroRF.datasets.neuroseed import get_training_data, get_testing_data\n",
    "    elif params[\"dataset_file\"] == \"datasets.polblogs_geomstats\":\n",
    "        from HoroRF.datasets.polblogs_geomstats import get_training_data, get_testing_data\n",
    "\n",
    "    # Get data\n",
    "    X_train, y_train = get_training_data(class_label=params[\"class_label\"], seed=params[\"seed\"])\n",
    "    X_train = convert(X_train.numpy(), \"poincare\", \"hyperboloid\")\n",
    "    X_test, y_test = get_testing_data(class_label=params[\"class_label\"], seed=params[\"seed\"])\n",
    "    X_test = convert(X_test.numpy(), \"poincare\", \"hyperboloid\")\n",
    "\n",
    "    # Hyperparams\n",
    "    args = {\n",
    "        \"n_estimators\": params[\"num_trees\"],\n",
    "        \"max_depth\": params[\"max_depth\"],\n",
    "        \"min_samples_leaf\": params[\"min_samples_leaf\"],\n",
    "    }\n",
    "\n",
    "    # 5-fold cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=params[\"seed\"])\n",
    "    f1_scores_hrf = []\n",
    "    f1_scores_rf = []\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        # Hyperbolic\n",
    "        hrf = HyperbolicRandomForestClassifier(**args)\n",
    "        hrf.fit(X_train[train_index], y_train[train_index], use_tqdm=True, seed=params[\"seed\"])\n",
    "        y_pred = hrf.predict(X_train[test_index])\n",
    "        f1_scores_hrf.append(f1_score(y_train[test_index], y_pred, average=\"micro\"))\n",
    "\n",
    "        # Euclidean\n",
    "        rf = RandomForestClassifier(**args, random_state=params[\"seed\"])\n",
    "        rf.fit(X_train[train_index], y_train[train_index])\n",
    "        y_pred = rf.predict(X_train[test_index])\n",
    "        f1_scores_rf.append(f1_score(y_train[test_index], y_pred, average=\"micro\"))\n",
    "\n",
    "    return f1_scores_hrf, f1_scores_rf\n",
    "\n",
    "\n",
    "f1_scores_hrf, f1_scores_rf = evaluate_hdt()\n",
    "print(f\"Hyperbolic: {np.mean(f1_scores_hrf):.3f} +/- {np.std(f1_scores_hrf):.3f}\")\n",
    "print(f\"Euclidean: {np.mean(f1_scores_rf):.3f} +/- {np.std(f1_scores_rf):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from HoroRF.datasets.gaussian import get_training_data, get_testing_data\n",
    "\n",
    "get_training_data(class_label=2, seed=0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([44, 44,  9, 22, 44, 44,  9, 44, 44,  9,  9, 22, 22, 44, 22, 44, 22, 22,\n",
       "        44, 22,  3, 22, 22, 44, 44, 44,  2,  3, 22, 22, 22,  2, 22,  2, 44, 44,\n",
       "        22,  9, 44, 44, 22, 44, 22, 22, 22,  9,  9, 44, 44, 22, 44,  3, 44, 22,\n",
       "         9, 43, 44, 22, 22, 44,  9,  3,  9,  2, 44, 43, 44, 22,  9,  3, 44,  9,\n",
       "        44, 44, 22,  9,  3,  3, 44,  2, 22,  2,  3, 22, 44,  3,  3,  3, 44, 44,\n",
       "        44,  2,  2, 22, 22, 22,  3,  2,  9, 22])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from HoroRF.datasets.neuroseed import get_training_data, get_testing_data\n",
    "\n",
    "get_training_data(class_label=2, seed=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['776992', '1050608', '190299', '358030', '239283', '4030157', '35786',\n",
       "       '174924', '370251', '191389',\n",
       "       ...\n",
       "       '268328', '228988', '155616', '158709', '299059', '515774', '311952',\n",
       "       '568082', '1112813', '562583'],\n",
       "      dtype='object', length=32863)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = adata.var[\"taxonomy_1\"]\n",
    "labels_counts = labels.value_counts()\n",
    "keep = labels_counts[labels_counts > 1000].index\n",
    "\n",
    "labels_filtered = labels[labels.isin(keep)]\n",
    "labels_filtered.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['145236', '4442899', '112801', '269532', '95741', '301910',\n",
       "       '74869', '1967053', '768535', '691952', '294040', '470879',\n",
       "       '358439', '95522', '268755', '4448558', '593016', '318205',\n",
       "       '4298060', '4475224', '1096766', '1108726', '3219862', '193763',\n",
       "       '2545365', '252198', '516020', '271500', '354401', '241499',\n",
       "       '4437436', '971971', '344456', '322087', '4371949', '554911',\n",
       "       '202816', '4444213', '4416974', '548878', '164915', '370295',\n",
       "       '4445508', '4321043', '4416763', '1087825', '997439', '4256699',\n",
       "       '3862524', '47181', '174004', '407459', '683241', '4364083',\n",
       "       '115049', '206331', '343699', '964799', '1667530', '4459355',\n",
       "       '583472', '4377731', '1105919', '814570', '709691', '145786',\n",
       "       '332210', '228043', '810672', '199344', '904468', '668257',\n",
       "       '4322804', '4320437', '4367317', '807112', '280233', '147940',\n",
       "       '1066654', '4469223', '563671', '2838675', '4468097', '4349553',\n",
       "       '1074801', '1117187', '998524', '4409486', '547904', '4438991',\n",
       "       '542729', '592901', '4478325', '1111892', '172081', '993372',\n",
       "       '510286', '726955', '755271', '2283850', '4455242', '4370941',\n",
       "       '301721', '175193', '613280', '3746876', '242138', '571103',\n",
       "       '300152', '4324420', '4418197', '4471635', '252702', '809489',\n",
       "       '561294', '814435', '4451215', '4349836', '642096', '270239',\n",
       "       '368338', '177555', '1108599', '655207', '868676'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "indices = np.random.choice(labels_filtered.index, 125, replace=False)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out error with my method:\n",
    "\n",
    "seed = 15\n",
    "dim = 4\n",
    "from HoroRF.datasets.neuroseed import get_training_data, get_testing_data\n",
    "from src.hyperdt.conversions import convert\n",
    "\n",
    "X, y = get_training_data(class_label=dim, seed=seed, num_samples=1000)\n",
    "X_h = convert(X.numpy(), \"poincare\", \"hyperboloid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:02<00:00,  9.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HyperbolicRandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HyperbolicRandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>HyperbolicRandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "HyperbolicRandomForestClassifier()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.hyperdt.forest import HyperbolicRandomForestClassifier\n",
    "\n",
    "hrf = HyperbolicRandomForestClassifier(n_estimators=24, max_depth=6)\n",
    "\n",
    "hrf.fit(X_h, y.numpy(), use_tqdm=True, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.045"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y.numpy(), hrf.predict(X_h), average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Troubleshooting poor neuroseed performance\n",
    "\n",
    "from HoroRF.datasets.neuroseed import get_training_data, get_testing_data\n",
    "from src.hyperdt.conversions import convert\n",
    "from src.hyperdt.tree import HyperbolicDecisionTreeClassifier\n",
    "\n",
    "X, y = get_training_data(class_label=2, seed=0, num_samples=400)\n",
    "X_h = convert(X.numpy(), \"poincare\", \"hyperboloid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 46.29it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sum() received an invalid combination of arguments - got (out=NoneType, axis=int, ), but expected one of:\n * (*, torch.dtype dtype)\n      didn't match because some of the keywords were incorrect: out, axis\n * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)\n * (tuple of names dim, bool keepdim, *, torch.dtype dtype)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/phil/mambaforge/envs/hdt/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"/home/phil/mambaforge/envs/hdt/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/phil/mambaforge/envs/hdt/lib/python3.11/site-packages/joblib/parallel.py\", line 588, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/phil/mambaforge/envs/hdt/lib/python3.11/site-packages/joblib/parallel.py\", line 588, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/phil/hdt/src/hyperdt/tree.py\", line 239, in fit\n    self._validate_hyperbolic(X)\n  File \"/home/phil/hdt/src/hyperdt/tree.py\", line 207, in _validate_hyperbolic\n    np.sum(X_spacelike**2, axis=1) - X[:, self.timelike_dim] ** 2,\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/phil/mambaforge/envs/hdt/lib/python3.11/site-packages/numpy/core/fromnumeric.py\", line 2313, in sum\n    return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/phil/mambaforge/envs/hdt/lib/python3.11/site-packages/numpy/core/fromnumeric.py\", line 86, in _wrapreduction\n    return reduction(axis=axis, out=out, **passkwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: sum() received an invalid combination of arguments - got (out=NoneType, axis=int, ), but expected one of:\n * (*, torch.dtype dtype)\n      didn't match because some of the keywords were incorrect: out, axis\n * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)\n * (tuple of names dim, bool keepdim, *, torch.dtype dtype)\n\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/phil/hdt/19_hororf.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beumaeus/home/phil/hdt/19_hororf.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m hrf \u001b[39m=\u001b[39m HyperbolicRandomForestClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beumaeus/home/phil/hdt/19_hororf.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mfor\u001b[39;00m train_index, test_index \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Beumaeus/home/phil/hdt/19_hororf.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     hrf\u001b[39m.\u001b[39mfit(X[train_index], y[train_index], use_tqdm\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, seed\u001b[39m=\u001b[39mseed)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beumaeus/home/phil/hdt/19_hororf.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m hrf\u001b[39m.\u001b[39mpredict(X[test_index])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beumaeus/home/phil/hdt/19_hororf.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39mprint\u001b[39m(f1_score(y[test_index], y_pred, average\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmicro\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[0;32m~/hdt/src/hyperdt/forest.py:58\u001b[0m, in \u001b[0;36mRandomForestClassifier.fit\u001b[0;34m(self, X, y, use_tqdm, seed)\u001b[0m\n\u001b[1;32m     56\u001b[0m trees \u001b[39m=\u001b[39m tqdm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrees) \u001b[39mif\u001b[39;00m use_tqdm \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrees\n\u001b[1;32m     57\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 58\u001b[0m     fitted_trees \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)(\n\u001b[1;32m     59\u001b[0m         delayed(tree\u001b[39m.\u001b[39mfit)(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_subsample(X, y)) \u001b[39mfor\u001b[39;00m tree \u001b[39min\u001b[39;00m trees\n\u001b[1;32m     60\u001b[0m     )\n\u001b[1;32m     61\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrees \u001b[39m=\u001b[39m fitted_trees\n\u001b[1;32m     62\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/hdt/lib/python3.11/site-packages/joblib/parallel.py:1944\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1938\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1939\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1940\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1941\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1942\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1944\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/mambaforge/envs/hdt/lib/python3.11/site-packages/joblib/parallel.py:1587\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1584\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m   1586\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1587\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[1;32m   1589\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1590\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1591\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1593\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/hdt/lib/python3.11/site-packages/joblib/parallel.py:1691\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1684\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1685\u001b[0m \n\u001b[1;32m   1686\u001b[0m     \u001b[39m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m     \u001b[39m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m     \u001b[39m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1689\u001b[0m     \u001b[39m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1690\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aborting:\n\u001b[0;32m-> 1691\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_error_fast()\n\u001b[1;32m   1692\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1694\u001b[0m     \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m     \u001b[39m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/hdt/lib/python3.11/site-packages/joblib/parallel.py:1726\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[39m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m \u001b[39m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m \u001b[39m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1725\u001b[0m \u001b[39mif\u001b[39;00m error_job \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1726\u001b[0m     error_job\u001b[39m.\u001b[39mget_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/mambaforge/envs/hdt/lib/python3.11/site-packages/joblib/parallel.py:735\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    729\u001b[0m backend \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparallel\u001b[39m.\u001b[39m_backend\n\u001b[1;32m    731\u001b[0m \u001b[39mif\u001b[39;00m backend\u001b[39m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    732\u001b[0m     \u001b[39m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     \u001b[39m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     \u001b[39m# be returned.\u001b[39;00m\n\u001b[0;32m--> 735\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return_or_raise()\n\u001b[1;32m    737\u001b[0m \u001b[39m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/hdt/lib/python3.11/site-packages/joblib/parallel.py:753\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    752\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 753\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n\u001b[1;32m    754\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n\u001b[1;32m    755\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: sum() received an invalid combination of arguments - got (out=NoneType, axis=int, ), but expected one of:\n * (*, torch.dtype dtype)\n      didn't match because some of the keywords were incorrect: out, axis\n * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)\n * (tuple of names dim, bool keepdim, *, torch.dtype dtype)\n"
     ]
    }
   ],
   "source": [
    "# So here's somewhere we fail:\n",
    "# n = 400, seed = 1, dim = 8\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from src.hyperdt.forest import HyperbolicRandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "n = 400\n",
    "seed = 1\n",
    "dim = 8\n",
    "\n",
    "X, y = get_training_data(class_label=dim, seed=seed, num_samples=n)\n",
    "X_h = convert(X.numpy(), \"poincare\", \"hyperboloid\")\n",
    "y = y.numpy()\n",
    "# Relabel\n",
    "_, y = np.unique(y, return_inverse=True)\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "hrf = HyperbolicRandomForestClassifier(n_estimators=1, max_depth=6)\n",
    "\n",
    "for train_index, test_index in cv.split(X):\n",
    "    hrf.fit(X[train_index], y[train_index], use_tqdm=True, seed=seed)\n",
    "    y_pred = hrf.predict(X[test_index])\n",
    "    print(f1_score(y[test_index], y_pred, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrf = HyperbolicRandomForestClassifier(n_estimators=1, max_depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrf.fit(X_h, y)\n",
    "\n",
    "f1_score(y, hrf.predict(X_h), average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  9, 22, 43, 44])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "reference = hrf.trees[0].classes_\n",
    "\n",
    "assert np.all(reference == hrf.classes_)\n",
    "assert np.all(reference == [tree.classes_ for tree in hrf.trees])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HyperbolicRandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HyperbolicRandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>HyperbolicRandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "HyperbolicRandomForestClassifier()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's step through each method, I guess\n",
    "\n",
    "from src.hyperdt.tree import HyperbolicDecisionTreeClassifier\n",
    "\n",
    "X, y = get_training_data(class_label=4, seed=15, num_samples=1000)\n",
    "X_h = convert(X.numpy(), \"poincare\", \"hyperboloid\")\n",
    "hdt = HyperbolicRandomForestClassifier(max_depth=6)\n",
    "hdt.fit(X_h, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 9 is out of bounds for axis 0 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/phil/hdt/19_hororf.ipynb Cell 27\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Beumaeus/home/phil/hdt/19_hororf.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m f1_score\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Beumaeus/home/phil/hdt/19_hororf.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m y_pred \u001b[39m=\u001b[39m hdt\u001b[39m.\u001b[39mpredict(X_h)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Beumaeus/home/phil/hdt/19_hororf.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m f1_score(y, hdt\u001b[39m.\u001b[39mclasses_[y_pred], average\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmicro\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 9 is out of bounds for axis 0 with size 6"
     ]
    }
   ],
   "source": [
    "# First up, we see that f1 score is messed up:\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_pred = hdt.predict(X_h)\n",
    "f1_score(y, hdt.classes_[y_pred], average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  9, 22, 43, 44])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdt.trees[0].classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  9, 22, 43, 44])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdt.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  9, 22, 43, 44])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86875"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdt2 = HyperbolicDecisionTreeClassifier()\n",
    "hdt2.fit(X_h, y)\n",
    "f1_score(hdt2.predict(X_h), y, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02375"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrf2 = HyperbolicRandomForestClassifier()\n",
    "hrf2.fit(X_h, y)\n",
    "f1_score(hrf2.predict(X_h), y, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02375"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So retraining the tree gives us the same issue:\n",
    "hrf2.trees[0].fit(X_h, y)\n",
    "f1_score(hrf2.trees[0].predict(X_h), y, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04875, 0.06875, 0.16625, 0.3575 , 0.02625, 0.3325 ])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrf2.trees[0]._get_probs(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "src.hyperdt.tree.DecisionTreeClassifier"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(hrf2.trees[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Points must lie on a hyperboloid: Lorentzian Inner Product does not equal the curvature of 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/phil/hdt/src/hyperdt/tree.py\", line 206, in _validate_hyperbolic\n    assert np.allclose(\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/phil/mambaforge/envs/hdt/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"/home/phil/mambaforge/envs/hdt/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/phil/mambaforge/envs/hdt/lib/python3.11/site-packages/joblib/parallel.py\", line 588, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/phil/mambaforge/envs/hdt/lib/python3.11/site-packages/joblib/parallel.py\", line 588, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/phil/hdt/src/hyperdt/tree.py\", line 239, in fit\n    self._validate_hyperbolic(X)\n  File \"/home/phil/hdt/src/hyperdt/tree.py\", line 212, in _validate_hyperbolic\n    raise ValueError(\"Points must lie on a hyperboloid: Lorentzian Inner Product does not equal the curvature of {}.\".format(self.curvature))\nValueError: Points must lie on a hyperboloid: Lorentzian Inner Product does not equal the curvature of 1.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/phil/hdt/19_hororf.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beumaeus/home/phil/hdt/19_hororf.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhyperdt\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mforest\u001b[39;00m \u001b[39mimport\u001b[39;00m HyperbolicRandomForestClassifier\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beumaeus/home/phil/hdt/19_hororf.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m hrf \u001b[39m=\u001b[39m HyperbolicRandomForestClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Beumaeus/home/phil/hdt/19_hororf.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m hrf\u001b[39m.\u001b[39mfit(X, y)\n",
      "File \u001b[0;32m~/hdt/src/hyperdt/forest.py:58\u001b[0m, in \u001b[0;36mRandomForestClassifier.fit\u001b[0;34m(self, X, y, use_tqdm, seed)\u001b[0m\n\u001b[1;32m     56\u001b[0m trees \u001b[39m=\u001b[39m tqdm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrees) \u001b[39mif\u001b[39;00m use_tqdm \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrees\n\u001b[1;32m     57\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 58\u001b[0m     fitted_trees \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)(\n\u001b[1;32m     59\u001b[0m         delayed(tree\u001b[39m.\u001b[39mfit)(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_subsample(X, y)) \u001b[39mfor\u001b[39;00m tree \u001b[39min\u001b[39;00m trees\n\u001b[1;32m     60\u001b[0m     )\n\u001b[1;32m     61\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrees \u001b[39m=\u001b[39m fitted_trees\n\u001b[1;32m     62\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/hdt/lib/python3.11/site-packages/joblib/parallel.py:1944\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1938\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1939\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1940\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1941\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1942\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1944\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/mambaforge/envs/hdt/lib/python3.11/site-packages/joblib/parallel.py:1587\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1584\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m   1586\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1587\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[1;32m   1589\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1590\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1591\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1593\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/hdt/lib/python3.11/site-packages/joblib/parallel.py:1691\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1684\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1685\u001b[0m \n\u001b[1;32m   1686\u001b[0m     \u001b[39m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m     \u001b[39m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m     \u001b[39m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1689\u001b[0m     \u001b[39m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1690\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aborting:\n\u001b[0;32m-> 1691\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_error_fast()\n\u001b[1;32m   1692\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1694\u001b[0m     \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m     \u001b[39m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/hdt/lib/python3.11/site-packages/joblib/parallel.py:1726\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[39m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m \u001b[39m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m \u001b[39m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1725\u001b[0m \u001b[39mif\u001b[39;00m error_job \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1726\u001b[0m     error_job\u001b[39m.\u001b[39mget_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/mambaforge/envs/hdt/lib/python3.11/site-packages/joblib/parallel.py:735\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    729\u001b[0m backend \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparallel\u001b[39m.\u001b[39m_backend\n\u001b[1;32m    731\u001b[0m \u001b[39mif\u001b[39;00m backend\u001b[39m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    732\u001b[0m     \u001b[39m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     \u001b[39m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     \u001b[39m# be returned.\u001b[39;00m\n\u001b[0;32m--> 735\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return_or_raise()\n\u001b[1;32m    737\u001b[0m \u001b[39m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/hdt/lib/python3.11/site-packages/joblib/parallel.py:753\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    752\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 753\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n\u001b[1;32m    754\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n\u001b[1;32m    755\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Points must lie on a hyperboloid: Lorentzian Inner Product does not equal the curvature of 1."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "seed = 0\n",
    "dim = 8\n",
    "\n",
    "from HoroRF.datasets.gaussian import get_training_data, get_testing_data\n",
    "\n",
    "X, y = get_training_data(class_label=dim, seed=seed, num_samples=1000, convert=False)\n",
    "X = X.numpy()\n",
    "y = y.numpy()\n",
    "# X_h = convert(X.numpy(), \"poincare\", \"hyperboloid\")\n",
    "\n",
    "from src.hyperdt.forest import HyperbolicRandomForestClassifier\n",
    "\n",
    "hrf = HyperbolicRandomForestClassifier(n_estimators=1, max_depth=6)\n",
    "hrf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.        , -1.015625  , -1.        , -1.        , -0.99999952,\n",
       "       -1.        , -1.        , -1.00000095, -1.        , -1.        ,\n",
       "       -1.00000381, -1.00000012, -1.        , -1.        , -1.        ,\n",
       "       -1.00000006, -1.        , -1.00000763, -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -0.99999237, -1.        ,\n",
       "       -0.99999619, -1.        , -1.        , -1.015625  , -1.        ,\n",
       "       -0.99999976, -0.99999999, -1.        , -1.        , -1.00001526,\n",
       "       -0.99999997, -1.        , -1.        , -1.00000012, -1.        ,\n",
       "       -1.00000048, -1.        , -1.        , -1.00000381, -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.00000191, -1.        ,\n",
       "       -1.00000012, -0.99999999, -1.        , -1.        , -0.99999999,\n",
       "       -1.        , -1.        , -1.        , -1.00000048, -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -0.99999999, -0.9921875 , -1.00000381,\n",
       "       -1.00000191, -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.        , -0.99902344,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.00000003, -0.99999952, -1.        ,\n",
       "       -1.        , -1.        , -0.99999997, -1.        , -1.00048828,\n",
       "       -1.        , -1.        , -1.        , -1.00000006, -0.99804688,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -0.99999952, -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.00000001, -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.00000001, -1.        ,\n",
       "       -1.        , -1.        , -1.        , -0.99999952, -1.        ,\n",
       "       -1.        , -1.        , -1.00000001, -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.        , -0.99975586,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -0.99999999, -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.00000002, -1.        , -0.99999905, -1.        ,\n",
       "       -0.99999237, -1.        , -1.        , -0.99999999, -1.        ,\n",
       "       -1.        , -1.00000006, -1.        , -1.00195312, -1.        ,\n",
       "       -1.        , -1.5       , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -0.99999237, -1.00006104, -1.        , -0.99999999,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.00000191, -1.00000048, -1.        , -1.        ,\n",
       "       -0.99999905, -1.00000095, -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.00000006, -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.        , -0.99999999,\n",
       "       -1.00000012, -1.        , -1.00000003, -1.        , -1.00000048,\n",
       "       -1.        , -1.        , -0.99999997, -1.00000001, -1.        ,\n",
       "       -1.00000024, -1.00000001, -0.99999619, -1.        , -1.        ,\n",
       "       -1.        , -0.99987793, -1.        , -1.        , -1.        ,\n",
       "       -0.99999988, -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.00000003, -1.        , -1.        ,\n",
       "       -0.99609375, -1.        , -1.        , -0.99999619, -0.99999619,\n",
       "       -1.00000048, -1.        , -1.        , -1.        , -1.00000001,\n",
       "       -1.        , -1.        , -1.        , -1.00000095, -0.99999809,\n",
       "       -1.        , -1.        , -1.00000001, -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.00000012, -0.99998474,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -0.99999999, -1.        , -1.        , -1.        , -1.        ,\n",
       "       -0.99999994, -1.00000012, -1.        , -1.        , -1.        ,\n",
       "       -0.99999999, -1.        , -1.00000012, -1.        , -0.99999988,\n",
       "       -0.99975586, -1.        , -1.        , -0.99999994, -0.99999809,\n",
       "       -1.        , -0.99999994, -1.00000024, -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.00000381, -0.99999999,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.00097656,\n",
       "       -1.        , -1.        , -1.        , -0.99975586, -1.        ,\n",
       "       -0.99999988, -1.        , -0.99999999, -0.99999619, -1.00000018,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -0.984375  , -1.        , -0.99999976, -1.        ,\n",
       "       -1.        , -1.00048828, -0.99999997, -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -0.99999988, -1.        ,\n",
       "       -1.        , -1.00000006, -1.        , -1.        , -1.        ,\n",
       "       -1.        , -0.99999999, -1.        , -1.00000191, -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -0.99999619, -1.        , -1.        , -1.00000006,\n",
       "       -1.00000024, -1.        , -1.        , -1.00000095, -1.        ,\n",
       "       -1.00000001, -1.0078125 , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.00000001, -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.00000003, -0.99987793,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.00000012, -0.99999999, -1.        , -1.00001526, -0.99993896,\n",
       "       -1.00001526, -0.99999952, -1.        , -1.        , -0.99999994,\n",
       "       -1.        , -1.        , -1.        , -0.99999976, -0.99999999,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -0.99987793, -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.00000006, -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -0.99996948, -1.        ,\n",
       "       -0.99999999, -1.00000003, -1.        , -1.        , -0.99902344,\n",
       "       -1.0078125 , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.00000001,\n",
       "       -0.99999619,  0.        , -0.99999905, -0.99999999, -1.00000001,\n",
       "       -1.00000001, -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -0.99999999, -1.00000191, -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.00000001, -1.        ,\n",
       "       -1.        , -1.00000381, -1.        , -1.        , -1.00000003,\n",
       "       -0.99999988, -1.00000048, -0.99999988, -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -0.99999988, -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.00000012, -1.        , -1.        , -1.        , -1.        ,\n",
       "       -0.99951172, -0.99999237, -1.        , -1.        , -0.99999988,\n",
       "       -1.        , -0.99999619, -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.00195312, -1.        , -0.99999999,\n",
       "       -1.        , -1.        , -1.00000001, -1.        , -1.        ,\n",
       "       -1.00003052, -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.015625  , -1.        , -1.        , -1.        , -0.99998474,\n",
       "       -0.99999976, -1.        , -0.99999982, -1.00000006, -1.        ,\n",
       "       -1.        , -0.99975586, -1.00000006, -1.        , -1.        ,\n",
       "       -1.        , -1.00000003, -1.        , -1.        , -1.        ,\n",
       "       -1.00000001, -0.99999619, -1.        , -1.        , -1.        ,\n",
       "       -1.00000006, -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.00000191, -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.015625  , -0.99999999, -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -0.99999997, -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.00003052, -1.        ,\n",
       "       -0.99999857, -1.        , -1.        , -1.00000024, -1.00000024,\n",
       "       -1.        , -0.99999976, -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.00000006, -1.        , -1.        , -1.25      ,\n",
       "       -1.        , -1.        , -1.00000072, -1.        , -0.99999997,\n",
       "       -1.        , -1.00000024, -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.00000381,\n",
       "       -1.        , -1.        , -1.00000095, -1.        , -1.00000001,\n",
       "       -1.00000095, -1.        , -0.99902344, -1.00006104, -1.        ,\n",
       "       -1.00000001, -0.99996948, -1.00012207, -0.99999997, -0.99999905,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.00000003, -0.99902344, -1.        ,\n",
       "       -1.        , -1.00000006, -1.        , -0.99999999, -1.        ,\n",
       "       -1.        , -1.        , -1.        , -0.99951172, -1.00000006,\n",
       "       -0.99999999, -0.99951172, -1.        , -1.        , -1.00000006,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.00000572,\n",
       "       -1.        , -1.        , -0.99999999, -1.        , -1.        ,\n",
       "       -1.        , -1.        , -0.99999997, -1.        , -1.        ,\n",
       "       -1.        , -0.99999988, -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.00000006, -0.99999998,\n",
       "        8.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.00000003, -1.        , -0.99999809, -0.99993896, -1.00000024,\n",
       "       -1.        , -1.        , -1.00000001, -1.        , -1.        ,\n",
       "       -1.        , -0.99999976, -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.00003052, -1.00000003,\n",
       "       -1.        , -1.        , -1.00000003, -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.00000001, -1.        , -1.        , -1.        , -1.        ,\n",
       "       -0.99999999, -1.        , -1.        , -1.        , -1.        ,\n",
       "       -0.99999997, -1.        , -1.        , -1.00000095, -1.        ,\n",
       "       -1.        , -1.        , -1.        , -0.99999988, -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.00000006, -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.00024414, -1.        , -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.00000003, -1.        , -1.        ,\n",
       "       -0.99999237, -1.        , -1.        , -1.00000024, -1.        ,\n",
       "       -1.00000024, -1.        , -0.99999994, -1.        , -1.00001526,\n",
       "       -1.        , -1.        , -1.00000191, -1.        , -1.        ,\n",
       "       -0.99975586, -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.00024414, -1.00000095, -1.        , -1.        , -1.        ,\n",
       "       -1.00000095, -1.        , -1.        , -1.        , -1.        ,\n",
       "       -1.00000191, -1.        , -1.        , -1.00024414, -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.00000381, -1.        ,\n",
       "       -0.99999997, -1.        , -1.00000003, -1.        , -1.        ,\n",
       "       -1.        , -1.        , -1.        , -1.        , -1.        ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(X[:, 1:] ** 2, axis=1) - X[:, 0] ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
