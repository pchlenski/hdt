{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HoroRF\n",
    "> Comparing two hyperbolic RF methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m2023-09-18 09:03:44,089 [hororf.rf_trainer]\u001b[0m 1 GPUs available\n",
      "\u001b[32;1m2023-09-18 09:03:44,089 [hororf.rf_trainer]\u001b[0m Using seed 17 on class 2\n",
      "\u001b[32;1m2023-09-18 09:03:44,094 [hororf.utils]\u001b[0m 977 datapoints in dataset 'datasets.polblogs_geomstats'\n",
      "\u001b[32;1m2023-09-18 09:03:44,094 [hororf.utils]\u001b[0m 977 datapoints in test dataset 'datasets.polblogs_geomstats'\n",
      "\u001b[32;1m2023-09-18 09:03:44,095 [hororf.rf_trainer]\u001b[0m 781 train and 196 test samples for fold 0\n",
      "\u001b[32;1m2023-09-18 09:06:06,657 [hororf.rf_trainer]\u001b[0m Hyperbolic tree f1 micro: 0.8878, f1 macro: 0.8870, AUPR: 0.0000. Mean depth of 6.00\n",
      "\u001b[32;1m2023-09-18 09:06:06,658 [hororf.rf_trainer]\u001b[0m 781 train and 196 test samples for fold 1\n",
      "\u001b[32;1m2023-09-18 09:08:48,420 [hororf.rf_trainer]\u001b[0m Hyperbolic tree f1 micro: 0.9337, f1 macro: 0.9332, AUPR: 0.0000. Mean depth of 6.00\n",
      "\u001b[32;1m2023-09-18 09:08:48,421 [hororf.rf_trainer]\u001b[0m 782 train and 195 test samples for fold 2\n",
      "\u001b[32;1m2023-09-18 09:11:20,500 [hororf.rf_trainer]\u001b[0m Hyperbolic tree f1 micro: 0.9385, f1 macro: 0.9384, AUPR: 0.0000. Mean depth of 6.00\n",
      "\u001b[32;1m2023-09-18 09:11:20,501 [hororf.rf_trainer]\u001b[0m 782 train and 195 test samples for fold 3\n",
      "\u001b[32;1m2023-09-18 09:13:49,974 [hororf.rf_trainer]\u001b[0m Hyperbolic tree f1 micro: 0.8974, f1 macro: 0.8974, AUPR: 0.0000. Mean depth of 6.00\n",
      "\u001b[32;1m2023-09-18 09:13:49,975 [hororf.rf_trainer]\u001b[0m 782 train and 195 test samples for fold 4\n",
      "\u001b[32;1m2023-09-18 09:16:31,936 [hororf.rf_trainer]\u001b[0m Hyperbolic tree f1 micro: 0.9385, f1 macro: 0.9383, AUPR: 0.0000. Mean depth of 6.00\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Run HoroRF:at 1000 \n",
    "cd HoroRF\n",
    "/home/phil/mambaforge/envs/hdt/bin/python train_hyp_rf.py -h\n",
    "mv ./logs/output ./logs/output_$(date +%Y%m%d_%H%M%S)_hororf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hrf 99.79 0.25\n",
      "results_micro 98.66 0.90\n",
      "rf 99.79 0.25\n"
     ]
    }
   ],
   "source": [
    "# For using hororf outputs\n",
    "# vals = [\n",
    "#     0.8878, 0.9337, 0.9385, 0.8974, 0.9385\n",
    "# ]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "dim = 16\n",
    "dataname = \"gaussian\"\n",
    "# dataname = \"neuroseed\"\n",
    "\n",
    "for suffix in [\"hrf\", \"results_micro\", \"rf\"]:\n",
    "    vals = np.loadtxt(f\"./HoroRF/logs/big_bench/hororf_{dataname}_{dim}/{suffix}.txt\", delimiter=\"\\t\")\n",
    "    print(suffix, f\"{np.mean(vals) * 100:.2f}\", f\"{np.std(vals)*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loader from file: datasets.neuroseed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 28.18it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 28.01it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 30.22it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 28.65it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 29.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperbolic: 0.867 +/- 0.012\n",
      "Euclidean: 0.885 +/- 0.016\n"
     ]
    }
   ],
   "source": [
    "# For 16-dimensional embeddings, HoroRF had a micro-F1 score of 0.675. Let's try ours:\n",
    "\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from src.hyperdt.forest import HyperbolicRandomForestClassifier\n",
    "from src.hyperdt.conversions import convert\n",
    "\n",
    "# Read params from yml file\n",
    "\n",
    "\n",
    "def evaluate_hdt():\n",
    "    params = yaml.safe_load(open(\"HoroRF/params.yml\", \"r\"))\n",
    "\n",
    "    # Dataset\n",
    "    print(f\"Using loader from file: {params['dataset_file']}\")\n",
    "    print()  # For tqdm compatibility\n",
    "    if params[\"dataset_file\"] == \"datasets.gaussian\":\n",
    "        from HoroRF.datasets.gaussian import get_training_data, get_testing_data\n",
    "    elif params[\"dataset_file\"] == \"datasets.neuroseed\":\n",
    "        from HoroRF.datasets.neuroseed import get_training_data, get_testing_data\n",
    "    elif params[\"dataset_file\"] == \"datasets.polblogs_geomstats\":\n",
    "        from HoroRF.datasets.polblogs_geomstats import get_training_data, get_testing_data\n",
    "\n",
    "    # Get data\n",
    "    X_train, y_train = get_training_data(class_label=params[\"class_label\"], seed=params[\"seed\"])\n",
    "    X_train = convert(X_train.numpy(), \"poincare\", \"hyperboloid\")\n",
    "    X_test, y_test = get_testing_data(class_label=params[\"class_label\"], seed=params[\"seed\"])\n",
    "    X_test = convert(X_test.numpy(), \"poincare\", \"hyperboloid\")\n",
    "\n",
    "    # Hyperparams\n",
    "    args = {\n",
    "        \"n_estimators\": params[\"num_trees\"],\n",
    "        \"max_depth\": params[\"max_depth\"],\n",
    "        \"min_samples_leaf\": params[\"min_samples_leaf\"],\n",
    "    }\n",
    "\n",
    "    # 5-fold cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=params[\"seed\"])\n",
    "    f1_scores_hrf = []\n",
    "    f1_scores_rf = []\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        # Hyperbolic\n",
    "        hrf = HyperbolicRandomForestClassifier(**args)\n",
    "        hrf.fit(X_train[train_index], y_train[train_index], use_tqdm=True, seed=params[\"seed\"])\n",
    "        y_pred = hrf.predict(X_train[test_index])\n",
    "        f1_scores_hrf.append(f1_score(y_train[test_index], y_pred, average=\"micro\"))\n",
    "\n",
    "        # Euclidean\n",
    "        rf = RandomForestClassifier(**args, random_state=params[\"seed\"])\n",
    "        rf.fit(X_train[train_index], y_train[train_index])\n",
    "        y_pred = rf.predict(X_train[test_index])\n",
    "        f1_scores_rf.append(f1_score(y_train[test_index], y_pred, average=\"micro\"))\n",
    "\n",
    "    return f1_scores_hrf, f1_scores_rf\n",
    "\n",
    "\n",
    "f1_scores_hrf, f1_scores_rf = evaluate_hdt()\n",
    "print(f\"Hyperbolic: {np.mean(f1_scores_hrf):.3f} +/- {np.std(f1_scores_hrf):.3f}\")\n",
    "print(f\"Euclidean: {np.mean(f1_scores_rf):.3f} +/- {np.std(f1_scores_rf):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from HoroRF.datasets.gaussian import get_training_data, get_testing_data\n",
    "\n",
    "get_training_data(class_label=2, seed=0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([44, 44,  9, 22, 44, 44,  9, 44, 44,  9,  9, 22, 22, 44, 22, 44, 22, 22,\n",
       "        44, 22,  3, 22, 22, 44, 44, 44,  2,  3, 22, 22, 22,  2, 22,  2, 44, 44,\n",
       "        22,  9, 44, 44, 22, 44, 22, 22, 22,  9,  9, 44, 44, 22, 44,  3, 44, 22,\n",
       "         9, 43, 44, 22, 22, 44,  9,  3,  9,  2, 44, 43, 44, 22,  9,  3, 44,  9,\n",
       "        44, 44, 22,  9,  3,  3, 44,  2, 22,  2,  3, 22, 44,  3,  3,  3, 44, 44,\n",
       "        44,  2,  2, 22, 22, 22,  3,  2,  9, 22])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from HoroRF.datasets.neuroseed import get_training_data, get_testing_data\n",
    "\n",
    "get_training_data(class_label=2, seed=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['776992', '1050608', '190299', '358030', '239283', '4030157', '35786',\n",
       "       '174924', '370251', '191389',\n",
       "       ...\n",
       "       '268328', '228988', '155616', '158709', '299059', '515774', '311952',\n",
       "       '568082', '1112813', '562583'],\n",
       "      dtype='object', length=32863)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = adata.var[\"taxonomy_1\"]\n",
    "labels_counts = labels.value_counts()\n",
    "keep = labels_counts[labels_counts > 1000].index\n",
    "\n",
    "labels_filtered = labels[labels.isin(keep)]\n",
    "labels_filtered.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['145236', '4442899', '112801', '269532', '95741', '301910',\n",
       "       '74869', '1967053', '768535', '691952', '294040', '470879',\n",
       "       '358439', '95522', '268755', '4448558', '593016', '318205',\n",
       "       '4298060', '4475224', '1096766', '1108726', '3219862', '193763',\n",
       "       '2545365', '252198', '516020', '271500', '354401', '241499',\n",
       "       '4437436', '971971', '344456', '322087', '4371949', '554911',\n",
       "       '202816', '4444213', '4416974', '548878', '164915', '370295',\n",
       "       '4445508', '4321043', '4416763', '1087825', '997439', '4256699',\n",
       "       '3862524', '47181', '174004', '407459', '683241', '4364083',\n",
       "       '115049', '206331', '343699', '964799', '1667530', '4459355',\n",
       "       '583472', '4377731', '1105919', '814570', '709691', '145786',\n",
       "       '332210', '228043', '810672', '199344', '904468', '668257',\n",
       "       '4322804', '4320437', '4367317', '807112', '280233', '147940',\n",
       "       '1066654', '4469223', '563671', '2838675', '4468097', '4349553',\n",
       "       '1074801', '1117187', '998524', '4409486', '547904', '4438991',\n",
       "       '542729', '592901', '4478325', '1111892', '172081', '993372',\n",
       "       '510286', '726955', '755271', '2283850', '4455242', '4370941',\n",
       "       '301721', '175193', '613280', '3746876', '242138', '571103',\n",
       "       '300152', '4324420', '4418197', '4471635', '252702', '809489',\n",
       "       '561294', '814435', '4451215', '4349836', '642096', '270239',\n",
       "       '368338', '177555', '1108599', '655207', '868676'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "indices = np.random.choice(labels_filtered.index, 125, replace=False)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out error with my method:\n",
    "\n",
    "seed = 15\n",
    "dim = 4\n",
    "from HoroRF.datasets.neuroseed import get_training_data, get_testing_data\n",
    "\n",
    "X, y = get_training_data(class_label=dim, seed=seed, num_samples=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 15.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HyperbolicRandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HyperbolicRandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>HyperbolicRandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "HyperbolicRandomForestClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.hyperdt.forest import HyperbolicRandomForestClassifier\n",
    "\n",
    "hrf = HyperbolicRandomForestClassifier(n_estimators=24, max_depth=6)\n",
    "\n",
    "hrf.fit(X, y, use_tqdm=True, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 44,  9, 44, 44,  9, 44, 43,  9, 22, 44, 44, 44,  9, 44,  2,  2,\n",
       "        9,  9, 22, 22, 44,  2, 22, 44, 22, 22,  9, 22, 22, 44, 22, 22, 44,\n",
       "        9, 22, 22, 22,  3, 44, 22,  9, 22, 22,  3, 43, 44, 44, 22, 22,  9,\n",
       "       22, 22, 44, 22, 22, 22, 44, 22, 22, 22, 22,  9,  2, 22, 44, 44,  3,\n",
       "       22, 22, 44, 44, 44, 43, 44, 22, 22, 44, 22,  3, 22, 44, 44, 22, 44,\n",
       "       22, 22, 44, 44, 44, 44, 22, 44, 44,  3, 44,  3,  9, 44, 44, 44, 44,\n",
       "       22, 44, 44,  3, 22, 44, 22,  3, 22,  9, 44, 22, 22, 22, 22,  2, 44,\n",
       "        9,  9, 44, 22, 22, 22, 44, 43,  3, 44, 22, 22, 44, 44,  9, 44, 22,\n",
       "        9,  9,  9, 44, 22, 44, 22,  3, 22, 22, 22, 22,  9,  9,  9,  9,  9,\n",
       "       22, 44, 22, 22, 22, 22, 44, 44, 22,  9, 44, 22, 44, 22, 22, 43,  3,\n",
       "       44, 44, 44, 44, 44, 22, 44, 44, 44, 43, 44, 44,  9, 22, 22, 44,  3,\n",
       "        9, 44,  2, 22, 44, 44, 22, 22, 44, 44, 44, 22,  9,  2, 22, 22, 44,\n",
       "        3,  9, 22, 44, 22,  9, 22, 44, 44, 44,  9, 44,  3, 44, 22, 22, 44,\n",
       "       44, 44, 22, 44, 22,  3,  9, 22, 22,  9,  9, 22, 44, 22, 22, 44, 44,\n",
       "        9,  3, 22,  9, 22, 44, 44, 44, 44, 22, 22, 44, 22,  9, 44,  2, 44,\n",
       "       22, 22,  9, 22, 22, 22,  2, 44, 22, 44, 44, 44, 22, 22, 44, 22, 44,\n",
       "       44, 22, 22, 44, 22, 22, 22, 22,  9,  2, 22, 44,  2,  9, 44, 22,  2,\n",
       "        3, 44, 44,  9, 44, 22, 44, 22, 22, 44, 44, 44, 22, 22, 44, 44,  9,\n",
       "       22, 44, 44, 44, 44, 22, 22, 22,  9, 22, 22, 44, 22, 44, 22, 44, 22,\n",
       "       22,  3, 44, 22, 44, 44, 44,  2, 22, 44, 22, 22, 44, 44, 44, 22,  9,\n",
       "        3,  9, 22, 44, 44, 44,  3, 22,  9, 22, 44, 44, 22, 44, 22, 22, 44,\n",
       "       44, 44, 44,  9, 44, 22, 43, 22, 22,  3, 44,  3, 44, 44,  9, 44,  9,\n",
       "       44, 44,  3, 43, 44, 44, 22, 22, 44, 22,  9, 44, 44,  9, 44,  3, 22,\n",
       "        3, 22, 22, 44,  9, 44, 22, 22, 44,  9,  9, 44, 44, 44, 22, 22, 22,\n",
       "        3, 22, 22, 44, 44, 22,  3, 44,  2, 44,  3, 44,  3,  3, 44, 22,  9,\n",
       "        9,  9, 44, 22, 44,  9, 22,  9,  9, 22, 44, 22, 44,  9, 44, 44,  3,\n",
       "       44, 22, 43,  9, 44, 22, 22, 22, 22, 22, 22, 44,  9, 44, 44,  2, 22,\n",
       "       22,  9, 22, 44, 43, 22, 22, 44, 22,  3, 43, 22,  9, 22,  9, 43, 22,\n",
       "       44, 22, 22, 22,  9,  9, 22, 44, 22, 22, 44,  2, 22, 22, 44, 22,  3,\n",
       "        9, 22,  9,  9, 44, 22, 22, 44, 43, 44,  9, 44, 22, 22, 22,  9, 44,\n",
       "       44, 44, 44,  9, 22, 22, 22, 22, 44, 44, 22, 44, 44,  3, 22,  9,  3,\n",
       "       44, 44, 22, 44, 44, 22,  9, 22, 44, 44, 22,  9,  3,  9,  3, 43,  9,\n",
       "        9, 44,  9, 22, 44, 44, 44, 44,  9, 22, 22, 44, 44, 22, 22, 44, 44,\n",
       "        9, 44, 22, 22,  2, 44,  9, 44,  3,  9, 22, 22, 44, 44, 44, 22,  9,\n",
       "       44, 22,  9, 22, 44, 44, 22,  9, 44, 44, 22, 22, 22, 44, 22, 22, 22,\n",
       "       44,  9, 22, 22, 43, 44, 22, 22,  3, 22, 22, 43, 22, 44, 22,  9,  3,\n",
       "        9,  9,  9, 22,  9, 44, 22,  3, 22, 44, 44, 22, 22, 22, 44, 44,  3,\n",
       "       22, 44, 22, 22, 22, 22, 44, 44,  3, 22, 22])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_hdt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/phil/hdt/19_hororf.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Beumaeus/home/phil/hdt/19_hororf.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m evaluate_hdt()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate_hdt' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_hdt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
