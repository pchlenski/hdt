{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HoroRF\n",
    "> Comparing two hyperbolic RF methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m2023-09-18 09:03:44,089 [hororf.rf_trainer]\u001b[0m 1 GPUs available\n",
      "\u001b[32;1m2023-09-18 09:03:44,089 [hororf.rf_trainer]\u001b[0m Using seed 17 on class 2\n",
      "\u001b[32;1m2023-09-18 09:03:44,094 [hororf.utils]\u001b[0m 977 datapoints in dataset 'datasets.polblogs_geomstats'\n",
      "\u001b[32;1m2023-09-18 09:03:44,094 [hororf.utils]\u001b[0m 977 datapoints in test dataset 'datasets.polblogs_geomstats'\n",
      "\u001b[32;1m2023-09-18 09:03:44,095 [hororf.rf_trainer]\u001b[0m 781 train and 196 test samples for fold 0\n",
      "\u001b[32;1m2023-09-18 09:06:06,657 [hororf.rf_trainer]\u001b[0m Hyperbolic tree f1 micro: 0.8878, f1 macro: 0.8870, AUPR: 0.0000. Mean depth of 6.00\n",
      "\u001b[32;1m2023-09-18 09:06:06,658 [hororf.rf_trainer]\u001b[0m 781 train and 196 test samples for fold 1\n",
      "\u001b[32;1m2023-09-18 09:08:48,420 [hororf.rf_trainer]\u001b[0m Hyperbolic tree f1 micro: 0.9337, f1 macro: 0.9332, AUPR: 0.0000. Mean depth of 6.00\n",
      "\u001b[32;1m2023-09-18 09:08:48,421 [hororf.rf_trainer]\u001b[0m 782 train and 195 test samples for fold 2\n",
      "\u001b[32;1m2023-09-18 09:11:20,500 [hororf.rf_trainer]\u001b[0m Hyperbolic tree f1 micro: 0.9385, f1 macro: 0.9384, AUPR: 0.0000. Mean depth of 6.00\n",
      "\u001b[32;1m2023-09-18 09:11:20,501 [hororf.rf_trainer]\u001b[0m 782 train and 195 test samples for fold 3\n",
      "\u001b[32;1m2023-09-18 09:13:49,974 [hororf.rf_trainer]\u001b[0m Hyperbolic tree f1 micro: 0.8974, f1 macro: 0.8974, AUPR: 0.0000. Mean depth of 6.00\n",
      "\u001b[32;1m2023-09-18 09:13:49,975 [hororf.rf_trainer]\u001b[0m 782 train and 195 test samples for fold 4\n",
      "\u001b[32;1m2023-09-18 09:16:31,936 [hororf.rf_trainer]\u001b[0m Hyperbolic tree f1 micro: 0.9385, f1 macro: 0.9383, AUPR: 0.0000. Mean depth of 6.00\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Run HoroRF:at 1000 \n",
    "cd HoroRF\n",
    "/home/phil/mambaforge/envs/hdt/bin/python train_hyp_rf.py -h\n",
    "mv ./logs/output ./logs/output_$(date +%Y%m%d_%H%M%S)_hororf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hrf 71.25 8.48\n",
      "results_micro 67.50 12.12\n",
      "rf 76.25 10.00\n"
     ]
    }
   ],
   "source": [
    "# For using hororf outputs\n",
    "# vals = [\n",
    "#     0.8878, 0.9337, 0.9385, 0.8974, 0.9385\n",
    "# ]\n",
    "\n",
    "dim = 8\n",
    "dataname = \"neuroseed\"\n",
    "\n",
    "suffix = \"hrf\"\n",
    "# suffix = \"results_micro\"\n",
    "# suffix = \"rf\"\n",
    "\n",
    "for suffix in [\"hrf\", \"results_micro\", \"rf\"]:\n",
    "    vals = np.loadtxt(f\"./HoroRF/logs/big_bench/hororf_{dataname}_{dim}/{suffix}.txt\", delimiter=\"\\t\")\n",
    "    print(suffix, f\"{np.mean(vals) * 100:.2f}\", f\"{np.std(vals)*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loader from file: datasets.gaussian\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:02<00:00, 11.45it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 959.58it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 979.62it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 952.35it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 937.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperbolic: 0.988 +/- 0.025\n",
      "Euclidean: 0.988 +/- 0.025\n"
     ]
    }
   ],
   "source": [
    "# For 16-dimensional embeddings, HoroRF had a micro-F1 score of 0.675. Let's try ours:\n",
    "\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from src.hyperdt.forest import HyperbolicRandomForestClassifier\n",
    "from src.hyperdt.conversions import convert\n",
    "\n",
    "# Read params from yml file\n",
    "\n",
    "\n",
    "def evaluate_hdt():\n",
    "    params = yaml.safe_load(open(\"HoroRF/params.yml\", \"r\"))\n",
    "\n",
    "    # Dataset\n",
    "    print(f\"Using loader from file: {params['dataset_file']}\")\n",
    "    print()  # For tqdm compatibility\n",
    "    if params[\"dataset_file\"] == \"datasets.gaussian\":\n",
    "        from HoroRF.datasets.gaussian import get_training_data, get_testing_data\n",
    "    elif params[\"dataset_file\"] == \"datasets.neuroseed\":\n",
    "        from HoroRF.datasets.neuroseed import get_training_data, get_testing_data\n",
    "    elif params[\"dataset_file\"] == \"datasets.polblogs_geomstats\":\n",
    "        from HoroRF.datasets.polblogs_geomstats import get_training_data, get_testing_data\n",
    "\n",
    "    # Get data\n",
    "    X_train, y_train = get_training_data(class_label=params[\"class_label\"], seed=params[\"seed\"])\n",
    "    X_train = convert(X_train.numpy(), \"poincare\", \"hyperboloid\")\n",
    "    X_test, y_test = get_testing_data(class_label=params[\"class_label\"], seed=params[\"seed\"])\n",
    "    X_test = convert(X_test.numpy(), \"poincare\", \"hyperboloid\")\n",
    "\n",
    "    # Hyperparams\n",
    "    args = {\n",
    "        \"n_estimators\": params[\"num_trees\"],\n",
    "        \"max_depth\": params[\"max_depth\"],\n",
    "        \"min_samples_leaf\": params[\"min_samples_leaf\"],\n",
    "    }\n",
    "\n",
    "    # 5-fold cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=params[\"seed\"])\n",
    "    f1_scores_hrf = []\n",
    "    f1_scores_rf = []\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        # Hyperbolic\n",
    "        hrf = HyperbolicRandomForestClassifier(**args)\n",
    "        hrf.fit(X_train[train_index], y_train[train_index], use_tqdm=True, seed=params[\"seed\"])\n",
    "        y_pred = hrf.predict(X_train[test_index])\n",
    "        f1_scores_hrf.append(f1_score(y_train[test_index], y_pred, average=\"micro\"))\n",
    "\n",
    "        # Euclidean\n",
    "        rf = RandomForestClassifier(**args, random_state=params[\"seed\"])\n",
    "        rf.fit(X_train[train_index], y_train[train_index])\n",
    "        y_pred = rf.predict(X_train[test_index])\n",
    "        f1_scores_rf.append(f1_score(y_train[test_index], y_pred, average=\"micro\"))\n",
    "\n",
    "    return f1_scores_hrf, f1_scores_rf\n",
    "\n",
    "\n",
    "f1_scores_hrf, f1_scores_rf = evaluate_hdt()\n",
    "print(f\"Hyperbolic: {np.mean(f1_scores_hrf):.3f} +/- {np.std(f1_scores_hrf):.3f}\")\n",
    "print(f\"Euclidean: {np.mean(f1_scores_rf):.3f} +/- {np.std(f1_scores_rf):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
